<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.4.1/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.2/dist/mindar-image-aframe.prod.js"></script>
    <script src="https://unpkg.com/aframe-chromakey-material/dist/aframe-chromakey-material.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>
  
</head>
  <body>
    <a-scene mindar-image="imageTargetSrc: ./target.mind;" color-space="sRGB" renderer="colorManagement: true, physicallyCorrectLights" vr-mode-ui="enabled: false" device-orientation-permission-ui="enabled: false">
      
      <a-assets>
        <video id="vid" src="video.mp4" loop="true" crossorigin="anonymous"></video>
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

      <a-entity mindar-image-target="targetIndex: 0">
        <a-video id="ar-video" src="#vid" width="1" height="0.55" 
                 material="shader: chromakey; color: 0.1 0.9 0.2" 
                 position="0 0 0">
        </a-video>
      </a-entity>
    </a-scene>

    <script>
      // Simple Hand Gesture Simulation (Example: Play/Pause on click)
      // For full hand-tracking, you would integrate MediaPipe here.
      const videoElement = document.getElementById('vid');
const arVideoEntity = document.querySelector('#ar-video');

// 1. Setup MediaPipe Hands
const hands = new Hands({locateFile: (file) => {
  return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
}});

hands.setOptions({
  maxNumHands: 1,
  modelComplexity: 1,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});

// 2. Define the Gesture (Open Palm vs Fist)
hands.onResults((results) => {
  if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
    const landmarks = results.multiHandLandmarks[0];
    
    // Logic: If the tip of the middle finger (landmark 12) 
    // is higher than the base (landmark 9), the hand is open.
    const isHandOpen = landmarks[12].y < landmarks[9].y;

    if (isHandOpen) {
      videoElement.play();
      arVideoEntity.setAttribute('scale', '1.2 1.2 1.2'); // Pop up effect
    } else {
      videoElement.pause();
      arVideoEntity.setAttribute('scale', '1 1 1');
    }
  }
});

// 3. Connect AR Camera to Hand Tracking
const camera = new Camera(document.querySelector('video'), {
  onFrame: async () => {
    await hands.send({image: document.querySelector('video')});
  },
  width: 640,
  height: 480
});
camera.start();
    </script>
  </body>
</html>
